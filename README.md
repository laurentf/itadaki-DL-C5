# üçú Itadaki - Recipe Image Retrieval System

_"Itadaki" signifie "bon app√©tit" en japonais_

## üéì Projet de certification DEV IA - Alyra

Ce projet constitue le **projet final** de la certification **D√©veloppeur Intelligence Artificielle** d'Alyra. Il impl√©mente un syst√®me de recherche d'images de recettes utilisant l'apprentissage profond.

**Comp√©tences √©valu√©es (Bloc C5)** :

- **C1** : pr√©parer des donn√©es non structur√©es en les convertissant en donn√©es num√©riques
- **C2** : s√©lectionner l'algorithme d'apprentissage profond le plus adapt√©
- **C3** : entra√Æner un mod√®le d'apprentissage profond en optimisant une loss function
- **C4** : d√©ployer efficacement un mod√®le d'apprentissage profond

## üéØ Vue d'ensemble

Syst√®me d'intelligence artificielle qui **trouve des recettes similaires** √† partir d'images de nourriture. Il utilise EfficientNetB0 et l'apprentissage profond pour analyser des photos de plats et proposer des recettes correspondantes depuis une base de donn√©es de 13,000+ recettes.

## üìö √âvolution du projet - 4 notebooks progressifs

Ce projet documente une **approche it√©rative** d'am√©lioration continue, avec 4 notebooks montrant l'√©volution des techniques et des performances :

### 1. üî∏ Raw Model (`recipe_image_retrieval_raw.ipynb`)

**Premier essai - EfficientNet gel√©**

![Raw Model Architecture](reports/architecture_images/raw.png)

- **Approche** : utilisation d'EfficientNetB0 pr√©-entra√Æn√© **sans modification**
- **Architecture** : `EfficientNetB0 (frozen) ‚Üí GlobalAveragePooling ‚Üí Features (1280D)`
- **Technique** : extraction de features natives sans entra√Ænement suppl√©mentaire
- **Avantages** : rapide √† implementer, baseline solide
- **Limites** : pas optimis√© pour la similarit√© de recettes
- **Temps** : ~5 minutes setup

### 2. üî• Transfer Learning Simple (`recipe_image_retrieval_tl.ipynb`)

**Deuxi√®me approche - Transfer Learning avec sampling al√©atoire**

> _Architecture similaire au TL Hard ci-dessous, mais avec random sampling au lieu de hard negative mining_

- **Approche** : triplet Loss avec EfficientNet gel√© + t√™te personnalis√©e
- **Architecture** : `EfficientNetB0 (frozen) ‚Üí Custom Head (1024‚Üí512) ‚Üí L2 Norm`
- **Technique** :
  - **Random sampling** pour les triplets (anchor, positive, negative)
  - **Triplet Loss** avec margin = 0.3
  - M√©trique : `triplet_accuracy` (pos_sim > neg_sim)
- **Am√©lioration** : embeddings optimis√©s pour la similarit√© de recettes
- **Limite** : sampling al√©atoire pas optimal, m√©trique peu informative
- **Temps** : ~30-45 minutes

### 3. ‚ö° Transfer Learning Am√©lior√© (`recipe_image_retrieval_tl_hard.ipynb`)

**Troisi√®me approche - Negative Sampling**

![Transfer Learning Hard Architecture](reports/architecture_images/tl_hard.png)

- **Approche** : transfer Learning avec **hard negative mining**
- **Architecture** : identique au TL simple mais avec sampling intelligent
- **Technique** :
  - **Hard negative sampling** : s√©lection des n√©gatifs les plus difficiles
  - **Triplet margin accuracy** : mesure si `pos_sim - neg_sim > margin`
  - Am√©lioration de l'efficacit√© d'entra√Ænement
- **Avantages** :
  - apprentissage plus efficace avec exemples difficiles
  - m√©trique plus informative (respect du margin)
  - convergence plus rapide
- **Temps** : ~30-45 minutes (mais plus efficace)

### 4. üöÄ Fine-tuning 2 phases (`recipe_image_retrieval_ft_hard.ipynb`)

**Quatri√®me approche - Fine-tuning en 2 phases**

![Fine-tuning 2 phases Architecture](reports/architecture_images/ft_hard.png)

- **Approche** : fine-tuning en **2 phases** avec hard negative sampling
- **Architecture** :
  - **Phase 1** : transfer Learning (EfficientNet gel√© + Custom Head)
  - **Phase 2** : fine-tuning (40 couches EfficientNet d√©gel√©es)
- **Technique** :
  - **Phase 1** : entra√Ænement de la t√™te personnalis√©e uniquement
  - **Phase 2** : d√©gelage intelligent de 40 couches avec learning rates diff√©renti√©s
  - **Hard negative sampling** pour optimiser l'apprentissage
  - **Triplet margin accuracy** pour un suivi pr√©cis
- **Avantages** :
  - adaptation fine du backbone EfficientNet
  - performances maximales
  - entra√Ænement stable et contr√¥l√©
- **Temps** : ~1-2 heures

## üî¨ Comparaison des techniques et performances attendues

| Notebook        | Technique        | Sampling      | M√©trique                | Backbone            | Temps  | Performance   |
| --------------- | ---------------- | ------------- | ----------------------- | ------------------- | ------ | ------------- |
| **Raw**         | Features natives | -             | Similarit√© cosinus      | Gel√©                | 5 min  | üü° Baseline   |
| **TL Simple**   | Triplet Loss     | Random        | triplet_accuracy        | Gel√©                | 45 min | üü¢ Bonne      |
| **TL Hard**     | Triplet Loss     | Hard negative | triplet_margin_accuracy | Gel√©                | 45 min | üü¢ Tr√®s bonne |
| **FT 2 Phases** | Fine-tuning      | Hard negative | triplet_margin_accuracy | 40 couches d√©gel√©es | 1h30   | üü¢ Excellente |

## üõ†Ô∏è Installation

### Pr√©requis

- **Python 3.12+** install√©
- **Au moins 8GB de RAM** (recommand√© : 16GB+)
- **Espace disque** : ~5GB pour les donn√©es et mod√®les
- **GPU recommand√©** pour le fine-tuning

### Installation rapide

```bash
# 1. Cloner le projet
git clone [your-repo-url]
cd itadaki

# 2. Cr√©er l'environnement virtuel
python -m venv itadaki_env

# 3. Activer l'environnement
# Windows:
itadaki_env\Scripts\activate
# Linux/Mac:
source itadaki_env/bin/activate

# 4. Installer les d√©pendances
pip install --upgrade pip
pip install -r requirements.txt

# 5. Lancer Jupyter
jupyter notebook
```

## üìä Structure du projet

```
itadaki/
‚îú‚îÄ‚îÄ üìì NOTEBOOKS (Evolution Progressive)
‚îÇ   ‚îú‚îÄ‚îÄ recipe_image_retrieval_raw.ipynb         # ‚úÖ 1. EfficientNet gel√©
‚îÇ   ‚îú‚îÄ‚îÄ recipe_image_retrieval_tl.ipynb          # ‚úÖ 2. TL + Random sampling
‚îÇ   ‚îú‚îÄ‚îÄ recipe_image_retrieval_tl_hard.ipynb     # ‚úÖ 3. TL + Hard negative sampling
‚îÇ   ‚îî‚îÄ‚îÄ recipe_image_retrieval_ft_hard.ipynb     # ‚úÖ 4. Fine-tuning 2 phases
‚îú‚îÄ‚îÄ üìÅ MOD√àLES & DONN√âES ENTRA√éN√âS
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                     # üî∏ Raw Model (EfficientNet gel√©)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recipe_image_retrieval_model_raw.keras        # Mod√®le embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recipe_embeddings_database_raw.npy            # Base embeddings (1280D)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ recipe_embeddings_database_metadata_raw.pkl   # Metadata pour recherche
‚îÇ   ‚îú‚îÄ‚îÄ tl/                                      # üî• Transfer Learning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_embedding_recipe_image_retrieval_model_tl.keras  # Mod√®le embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recipe_embeddings_database_tl.npy                     # Base embeddings (512D)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ recipe_embeddings_database_metadata_tl.pkl            # Metadata pour recherche
‚îÇ   ‚îú‚îÄ‚îÄ ft/                                      # üöÄ Fine-tuning 2 phases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_embedding_recipe_image_retrieval_model_ft.keras  # Mod√®le embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recipe_embeddings_database_ft.npy                     # Base embeddings (512D)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ recipe_embeddings_database_metadata_ft.pkl            # Metadata pour recherche
‚îÇ   ‚îî‚îÄ‚îÄ data/                                    # üìä Dataset principal
‚îÇ       ‚îú‚îÄ‚îÄ recipes_with_images_dataframe.pkl   # DataFrame pickle (rechargement facile)
‚îÇ       ‚îî‚îÄ‚îÄ data.csv                             # Donn√©es CSV originales
‚îú‚îÄ‚îÄ üñºÔ∏è TESTS
‚îÇ   ‚îî‚îÄ‚îÄ test_recipes/                            # Images de test vari√©es
‚îú‚îÄ‚îÄ üìä RAPPORTS
‚îÇ   ‚îî‚îÄ‚îÄ reports/                                 # Analyses et visualisations
‚îÇ       ‚îî‚îÄ‚îÄ architecture_images/                 # Images d'architecture des mod√®les
‚îî‚îÄ‚îÄ üîß CONFIGURATION
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ README.md
```

### üîç D√©tail des dossiers de mod√®les

Chaque dossier de mod√®le (`raw/`, `tl/`, `ft/`) contient **3 fichiers essentiels** :

#### üì¶ **Mod√®le Embeddings** (`.keras`)

- **Raw** : `recipe_image_retrieval_model_raw.keras` - EfficientNet gel√© (1280D)
- **TL** : `best_embedding_recipe_image_retrieval_model_tl.keras` - TL optimis√© (512D)
- **FT** : `best_embedding_recipe_image_retrieval_model_ft.keras` - Fine-tuning 2 phases (512D)

#### üóÑÔ∏è **Base de donn√©es d'embeddings** (`.npy`)

- **Raw** : `recipe_embeddings_database_raw.npy` - 13,463 embeddings √ó 1280D
- **TL** : `recipe_embeddings_database_tl.npy` - 13,463 embeddings √ó 512D
- **FT** : `recipe_embeddings_database_ft.npy` - 13,463 embeddings √ó 512D

#### üìã **Metadata** (`.pkl`)

- **Raw** : `recipe_embeddings_database_metadata_raw.pkl` - Index ‚Üí recette mapping
- **TL** : `recipe_embeddings_database_metadata_tl.pkl` - Index ‚Üí recette mapping
- **FT** : `recipe_embeddings_database_metadata_ft.pkl` - Index ‚Üí recette mapping

#### üíæ **Dataset principal** (`data/`)

- **`recipes_with_images_dataframe.pkl`** : DataFrame pickle complet pour rechargement rapide
- **`data.csv`** : Donn√©es CSV originales du dataset Kaggle

## üöÄ Guide d'utilisation

### Approche recommand√©e : progression s√©quentielle

Pour comprendre l'√©volution du projet, il est recommand√© de suivre les notebooks dans l'ordre :

#### 1. Commencer par le Raw Model

```bash
jupyter notebook recipe_image_retrieval_raw.ipynb
```

- comprendre la baseline et l'extraction de features
- tester rapidement le syst√®me

#### 2. Continuer avec Transfer Learning Simple

```bash
jupyter notebook recipe_image_retrieval_tl.ipynb
```

- d√©couvrir le Triplet Loss et l'optimisation d'embeddings
- voir l'am√©lioration par rapport au raw model

#### 3. Am√©liorer avec Hard Negative Sampling

```bash
jupyter notebook recipe_image_retrieval_tl_hard.ipynb
```

- comprendre l'importance du sampling intelligent
- observer l'am√©lioration de l'efficacit√© d'entra√Ænement

#### 4. Finaliser avec Fine-tuning 2 phases

```bash
jupyter notebook recipe_image_retrieval_ft_hard.ipynb
```

- d√©couvrir le fine-tuning
- obtenir les meilleures performances

## üéØ Utilisation du syst√®me

### Interface commune √† tous les notebooks

```python
# 1. Charger votre image
query_image = "path/to/your/food_image.jpg"

# 2. Rechercher les recettes similaires
results = retrieval_system.search_similar_recipes(query_image, top_k=3)

# 3. Afficher les r√©sultats avec visualisations
retrieval_system.display_results(query_image, results)
```

### Fonctionnalit√©s avanc√©es

```python
# Visualiser l'architecture du mod√®le
retrieval_system.visualize_model_architecture()

# Analyser les triplets d'entra√Ænement
retrieval_system.show_triplets(num_triplets=3)

# √âvaluer les performances
retrieval_system.evaluate_model()
```

## üöÄ API de Production - FastAPI

En plus des notebooks de recherche, Itadaki dispose d'une **API FastAPI compl√®te** pr√™te pour la production qui permet d'utiliser le mod√®le fine-tun√© via HTTP.

### üèóÔ∏è Architecture de l'API

L'API suit une architecture **MVC** avec le pattern **Domain/Response** pour une s√©paration claire des responsabilit√©s :

```
api/
‚îú‚îÄ‚îÄ main.py                     # Point d'entr√©e FastAPI
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Configuration globale
‚îî‚îÄ‚îÄ features/
    ‚îî‚îÄ‚îÄ search/                # Feature de recherche de recettes
        ‚îú‚îÄ‚îÄ api/
        ‚îÇ   ‚îî‚îÄ‚îÄ search.py      # Contr√¥leur REST
        ‚îú‚îÄ‚îÄ services/
        ‚îÇ   ‚îî‚îÄ‚îÄ search_service.py  # Logique m√©tier
        ‚îú‚îÄ‚îÄ schemas/
        ‚îÇ   ‚îî‚îÄ‚îÄ search.py      # Models Pydantic (Request/Response/Domain)
        ‚îî‚îÄ‚îÄ utils/
            ‚îî‚îÄ‚îÄ model_loader.py    # Chargement et inf√©rence du mod√®le
```

### üîÑ Processus de Recherche de Recettes

#### 1. **Initialisation Compl√®te au D√©marrage**

```python
# √Ä l'initialisation de l'API (au d√©marrage) :
# - Chargement des embeddings pr√©-calcul√©s (13,463 √ó 512D)
# - Chargement des m√©tadonn√©es (chemins d'images, mapping)
# - Chargement du DataFrame des recettes
# - ‚ö° Chargement du mod√®le TensorFlow (production-ready!)
```

#### 2. **Traitement de l'Image Query (Mod√®le Pr√©-charg√©)**

```python
# Lors de CHAQUE recherche d'image :
def get_image_embedding(image):
    # Mod√®le d√©j√† charg√© et pr√™t √† l'emploi
    if self.model is None:
        raise ValueError("Model not loaded")  # Ne devrait jamais arriver

    # Preprocessing EfficientNet exact du notebook
    img_array = preprocess_input(image_resized)

    # Inf√©rence pour obtenir l'embedding
    embedding = self.model.predict(img_array)

    # Normalisation L2 (critique pour la similarit√© cosinus)
    return embedding / ||embedding||_2
```

#### 3. **Calcul de Similarit√©**

```python
# Similarit√© cosinus avec la base d'embeddings
similarities = cosine_similarity(query_embedding, embeddings_db)

# Tri et s√©lection des top-k plus similaires
top_indices = argsort(similarities)[::-1][:top_k]
```

#### 4. **Construction de la R√©ponse**

```python
# Enrichissement avec les d√©tails des recettes
results = []
for idx in top_indices:
    recipe_data = recipes_df.iloc[idx]
    results.append({
        'rank': rank,
        'title': recipe_data['Title'],
        'ingredients': recipe_data['Ingredients'],
        'instructions': recipe_data['Instructions'],
        'similarity': similarity_score,
        'imagePath': image_path
    })
```

### üì° Endpoints Disponibles

#### **POST** `/api/v1/search/search`

Recherche de recettes similaires √† partir d'une image

**Request:**

- `image`: Fichier image (multipart/form-data)
- `top_k`: Nombre de r√©sultats (1-10, d√©faut: 3)

**Response:**

```json
{
  "recipes": [
    {
      "rank": 1,
      "title": "Caramel Apple Cupcakes",
      "imagePath": "/path/to/image.jpg",
      "ingredients": "['ingredient1', 'ingredient2', ...]",
      "instructions": "Step by step instructions...",
      "similarity": 0.6209537386894226
    }
  ],
  "totalResults": 3,
  "processingTime": 2.34,
  "timestamp": "2025-07-18T04:15:30.946Z",
  "success": true,
  "errorMessage": null
}
```

#### **GET** `/docs`

Documentation Swagger interactive de l'API

### üöÄ Lancement de l'API

#### Installation et d√©marrage

```bash
# 1. Installer les d√©pendances
pip install -r requirements.txt

# 2. Aller dans le dossier API
cd api

# 3. Lancer le serveur
python -m uvicorn main:app --host 127.0.0.1 --port 8000 --reload
```

#### Test avec curl

```bash
# Test de recherche
curl -X POST "http://127.0.0.1:8000/api/v1/search/search" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@test_recipes/my_food_image.jpg" \
  -F "top_k=3"
```

### ‚ö° Performances et Optimisations

#### **Temps de R√©ponse**

- **D√©marrage API** : 15-20s (chargement complet : embeddings + mod√®le TensorFlow)
- **Tous les appels search** : 1-3s (performance constante et pr√©visible)

#### **Optimisations Production**

- **Chargement au d√©marrage** : Mod√®le TensorFlow pr√™t d√®s le lancement pour performance constante
- **Embeddings pr√©-calcul√©s** : Base de 13,463 embeddings pour √©viter l'inf√©rence massive
- **Singleton Pattern** : Une seule instance du service en m√©moire

#### **Optimisations Preprocessing**

- **EfficientNet preprocess_input** : Normalisation native identique au training
- **Normalisation L2** : Embedding query normalis√© pour similarit√© cosinus optimale
- **Custom Objects** : Chargement correct du mod√®le avec triplet loss et m√©triques

### üéØ Cas d'Usage Production

#### **Application Web**

```javascript
// Frontend: Upload d'image et recherche
const formData = new FormData();
formData.append("image", imageFile);
formData.append("top_k", 5);

const response = await fetch("/api/v1/search/search", {
  method: "POST",
  body: formData,
});

const results = await response.json();
// Afficher les recettes similaires trouv√©es
```

#### **Int√©gration Mobile**

- Endpoint REST standard compatible iOS/Android
- Support multipart/form-data pour upload d'images
- R√©ponses JSON structur√©es pour parsing facile

#### **Monitoring et Logs**

- Logs d√©taill√©s de performance et debugging
- M√©triques de similarit√© pour analyse qualit√©
- Gestion d'erreurs robuste avec codes HTTP appropri√©s

---

## üì• Dataset

**Food Ingredients and Recipe Dataset with Images** (Kaggle)

üîó **Lien Kaggle** : https://www.kaggle.com/datasets/pes12017000148/food-ingredients-and-recipe-dataset-with-images

- **13,463 recettes uniques** avec images HD
- **ingr√©dients d√©taill√©s** et instructions compl√®tes
- **images haute qualit√©** (224x224 minimum)
- **t√©l√©chargement automatique** via `kagglehub`
- **taille totale** : ~2GB

## üèóÔ∏è Choix d'architecture : pourquoi EfficientNetB0 ?

### üéØ Comparaison des architectures backbone

| Architecture                 | Param√®tres | Pr√©cision ImageNet | Temps inf√©rence | Avantages           | Inconv√©nients              |
| ---------------------------- | ---------- | ------------------ | --------------- | ------------------- | -------------------------- |
| **EfficientNetB0** ‚úÖ        | 5.3M       | 77.1%              | Rapide          | √âquilibre optimal   | Relativement r√©cent        |
| **ResNet50**                 | 25.6M      | 76.0%              | Moyen           | Tr√®s stable, prouv√© | Plus lourd, moins efficace |
| **MobileNetV2**              | 3.5M       | 71.8%              | Tr√®s rapide     | Tr√®s l√©ger          | Pr√©cision plus faible      |
| **Vision Transformer (ViT)** | 86M+       | 81.8%              | Lent            | SOTA pr√©cision      | Tr√®s gourmand, complexe    |

### üîç Justification du choix EfficientNetB0

#### ‚úÖ **Avantages d√©cisifs**

1. **üéØ √âquilibre optimal** : EfficientNetB0 offre le meilleur compromis pr√©cision/efficacit√©

   - **pr√©cision** : 77.1% sur ImageNet (sup√©rieure √† ResNet50 et MobileNet)
   - **efficacit√©** : 5.3M param√®tres seulement (5x moins que ResNet50)
   - **vitesse** : inf√©rence rapide adapt√©e √† la recherche de similarit√©

2. **üöÄ Architecture moderne** : compound scaling et optimisations avanc√©es

   - **compound scaling** : √©quilibre intelligente depth/width/resolution
   - **inverted bottlenecks** : efficacit√© computationnelle maximale
   - **squeeze-and-excitation** : attention sur les channels importants

3. **üîß Facilit√© d'int√©gration** : support natif TensorFlow/Keras
   - **pr√©-entra√Æn√© ImageNet** : features visuelles g√©n√©riques de qualit√©
   - **transfert learning** : adaptation facile pour les recettes
   - **compatibilit√©** : stable avec l'√©cosyst√®me TensorFlow

#### ‚ùå **Pourquoi pas les autres ?**

##### **ResNet50** - trop lourd pour le contexte

- **25.6M param√®tres** : 5x plus lourd qu'EfficientNet
- **pr√©cision inf√©rieure** : 76.0% vs 77.1% sur ImageNet
- **architecture plus ancienne** : moins d'optimisations modernes

##### **MobileNetV2** - pr√©cision insuffisante

- **pr√©cision limit√©e** : 71.8% sur ImageNet (6% de moins)
- **features moins riches** : impact sur la qualit√© des embeddings
- **optimis√© mobile** : pas n√©cessaire pour notre use case

##### **Vision Transformers (ViT)** - trop complexe pour d√©buter

- **üî• tr√®s gourmand** : 86M+ param√®tres (16x plus qu'EfficientNet)
- **üíª ressources importantes** : n√©cessite GPU puissant et beaucoup de RAM
- **‚ö° lent √† l'inf√©rence** : on voulait un syst√®me assez r√©actif
- **üß† complexit√© √©lev√©e** : architecture plus difficile √† comprendre/d√©boguer
- **üìä donn√©es n√©cessaires** : performances optimales avec datasets √©normes
- **üéì contexte apprentissage** : moins adapt√© pour une premi√®re approche

### üéØ Contexte du projet et contraintes

#### **Contraintes techniques**

- **üíª ressources limit√©es** : d√©veloppement sur hardware standard et cloud (mais budget limit√©)
- **‚è±Ô∏è temps de d√©veloppement** : formation intensive, it√©ration rapide n√©cessaire
- **üìö apprentissage progressif** : ma√Ætrise des concepts avant optimisations avanc√©es

#### **Objectifs p√©dagogiques**

- **üîç compr√©hension** : architecture simple √† analyser et expliquer
- **üõ†Ô∏è mise en pratique** : focus sur les techniques d'entra√Ænement (triplet loss) et quelques optimisations (hard negative mining)
- **üìà progression** : de la baseline vers le fine-tuning en 2 phases

### üí° √âvolution future possible

**Pour des performances maximales** (contexte production) :

- **EfficientNet-B2/B4** : compromis pr√©cision/efficacit√© sup√©rieur
- **dataset plus cons√©quent** : il y a une am√©lioration directe en rapport avec la quantit√© de donn√©es
- **ü§î utilisation de Food101 ?** : https://www.tensorflow.org/datasets/catalog/food101?hl=fr

#### ‚úÖ **Approche compl√©mentaire : Enrichissement par tags**

**üí° Id√©e cl√©e** : utiliser Food101 pour **enrichir** le dataset actuel avec des tags alimentaires !

##### **üéØ Strat√©gie d'enrichissement**

1. **üìã conserver le dataset actuel (ou √©quivalent plus cons√©quent)** : toutes les recettes avec m√©tadonn√©es
2. **üè∑Ô∏è ajouter des tags Food101** : classifier chaque image avec les 101 cat√©gories
3. **üîÑ cr√©er des triplets intelligents** : utiliser les tags pour un sampling plus pertinent

##### **üöÄ Avantages de cette approche**

1. **üéØ triplets plus coh√©rents** :

   - **anchor** : Pizza margherita
   - **positive** : Pizza 4 fromages (m√™me cat√©gorie visuelle)
   - **negative** : Sushi (cat√©gorie visuelle diff√©rente)

2. **üß† apprentissage plus efficace** :

   - triplets visuellement logiques
   - meilleure s√©paration des embeddings
   - convergence plus rapide

3. **üìä m√©triques am√©lior√©es** :

   - triplet margin accuracy plus √©lev√©e
   - similarit√© intra-classe renforc√©e
   - s√©paration inter-classe optimis√©e

4. **üîÑ sampling intelligent** :
   - remplacement du random sampling
   - alternative au hard negative mining
   - approche hybride : tags + difficult√©

## üîß Architecture technique d√©taill√©e

### Configuration par notebook

#### Raw Model

```python
CONFIG_RAW = {
    'IMG_SIZE': 224,
    'BATCH_SIZE': 32,
    'EMBEDDING_DIM': 1280,  # Features natives EfficientNet
}
```

#### Transfer Learning Simple

```python
CONFIG_TL = {
    'IMG_SIZE': 224,
    'BATCH_SIZE': 32,
    'EMBEDDING_DIM': 512,
    'TRIPLET_MARGIN': 0.3,
    'EPOCHS': 10,
    'SAMPLING': 'random'  # Random triplet sampling
}
```

#### Transfer Learning Hard

```python
CONFIG_TL_HARD = {
    'IMG_SIZE': 224,
    'BATCH_SIZE': 32s,
    'EMBEDDING_DIM': 512,
    'TRIPLET_MARGIN': 0.8,
    'EPOCHS': 15,
    'SAMPLING': 'hard_negative'  # Hard negative mining
}
```

#### Fine-tuning 2 phases

```python
CONFIG_FT = {
    'IMG_SIZE': 224,
    'BATCH_SIZE': 32,
    'EMBEDDING_DIM': 512,
    'TRIPLET_MARGIN': 0.8,
    'LAYERS_TO_UNFREEZE': 40,
    'PHASE_1_EPOCHS': 6,  # Transfer Learning
    'PHASE_2_EPOCHS': 20,  # Fine-tuning
    'SAMPLING': 'hard_negative'
}
```

## üìà √âvolution des performances

### M√©triques cl√©s

| Notebook    | M√©trique principale     | Dimension | Sampling      | Temps train |
| ----------- | ----------------------- | --------- | ------------- | ----------- |
| Raw         | N/A                     | 1280D     | N/A           | N/A         |
| TL Simple   | triplet_accuracy        | 512D      | Random        | 30 min      |
| TL Hard     | triplet_margin_accuracy | 512D      | Hard negative | 35 min      |
| FT 2 phases | triplet_margin_accuracy | 512D      | Hard negative | 90 min      |

### Am√©lioration progressive

1. **Raw ‚Üí TL Simple** : embeddings optimis√©s pour la similarit√©
2. **TL Simple ‚Üí TL Hard** : sampling intelligent + m√©trique plus pr√©cise
3. **TL Hard ‚Üí FT 2 phases** : adaptation fine du backbone pour performances maximales

## üñºÔ∏è Images de test

Le dossier `test_recipes/` contient des images vari√©es pour tester les diff√©rents mod√®les :

```python
# Exemple d'utilisation
test_image = "./test_recipes/1.jpg"
results = retrieval_system.search_similar_recipes(test_image, top_k=5)
```

## üîç Concepts cl√©s impl√©ment√©s

### 1. Triplet Loss

optimisation de la distance entre embeddings pour maximiser la similarit√© intra-classe et minimiser la similarit√© inter-classe.

### 2. Hard Negative Mining

s√©lection intelligente des exemples n√©gatifs les plus difficiles pour am√©liorer l'efficacit√© d'entra√Ænement.

### 3. Fine-tuning 2 phases

approche progressive : d'abord entra√Æner la t√™te personnalis√©e, puis adapter le backbone pr√©-entra√Æn√©.

### 4. Triplet Margin Accuracy

m√©trique avanc√©e qui mesure si la diff√©rence `pos_similarity - neg_similarity > margin`, plus informative que la Triplet Accuracy.

## üéØ R√©sultats et apprentissages

### Principales d√©couvertes

1. **Raw model** : baseline solide mais non optimis√©e
2. **Random Sampling** : efficace mais sous-optimal
3. **Hard Negative Mining** : am√©lioration significative de l'efficacit√©
4. **Fine-tuning 2 phases** : performances maximales avec contr√¥le total

### Recommandations

- **pour tests rapides** : utiliser le Raw Model
- **pour production** : Transfer Learning Hard est le meilleur compromis
- **pour recherche avanc√©e** : Fine-tuning 2 phases pour performances maximales

## üìö Technologies utilis√©es

- **TensorFlow/Keras** : framework d'apprentissage profond
- **EfficientNetB0** : architecture de backbone
- **OpenCV** : traitement d'images
- **Matplotlib/Seaborn** : visualisations
- **NumPy/Pandas** : manipulation de donn√©es
- **Kagglehub** : t√©l√©chargement de dataset

## üéì Conclusions

Ce projet d√©montre une approche m√©thodique d'am√©lioration continue en intelligence artificielle, depuis une baseline simple jusqu'√† des techniques avanc√©es de fine-tuning. Chaque notebook apporte des am√©liorations progressives et documente les apprentissages obtenus.

La progression **Raw ‚Üí TL Simple ‚Üí TL Hard ‚Üí FT 2 phases** illustre parfaitement comment optimiser graduellement un syst√®me d'apprentissage profond pour obtenir des performances maximales.

---

**Projet r√©alis√© dans le cadre de la certification pour la formation de D√©veloppeur IA - Alyra**
